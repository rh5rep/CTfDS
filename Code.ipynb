{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path_trump = path + \"\\\\data\\\\hashtag_donaldtrump.csv\"\n",
    "trump = pd.read_csv(path_trump, lineterminator=\"\\n\")\n",
    "path_biden = path + \"\\\\data\\\\hashtag_joebiden.csv\"\n",
    "biden = pd.read_csv(path_biden, lineterminator=\"\\n\")\n",
    "trump[\"source\"] = \"Trump\"\n",
    "biden[\"source\"] = \"Biden\"\n",
    "# Concatenate and remove duplicates\n",
    "df = pd.concat([trump, biden], ignore_index=True)\n",
    "df = df.drop_duplicates()\n",
    "df = df[df[\"country\"].isin([\"United States of America\", \"United States\"])].dropna(\n",
    "    subset=[\"state\"]\n",
    ")\n",
    "## Lower case all tweets\n",
    "# df[\"tweet\"] = df[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets containing Trump names but not Biden names, or vice versa: 199341\n",
      "Percentage of filtered tweets: 59.96%\n",
      "\n",
      "Number of tweets containing Trump names but not Biden names: 114507\n",
      "Percentage of filtered tweets Trump: 34.44%\n",
      "\n",
      "Number of tweets containing Biden names but not Trump names: 84834\n",
      "Percentage of filtered tweets Biden: 25.52%\n"
     ]
    }
   ],
   "source": [
    "frequent_names_trump = [\n",
    "    \"Trump\",\n",
    "    \"Donald\" \"Donald Trump\",\n",
    "    \"@realDonaldTrump\",\n",
    "    \"The Donald\",\n",
    "    \"45\",\n",
    "    \"Donald J. Trump\",\n",
    "    \"DJT\",\n",
    "    \"The Trump Administration\",\n",
    "    \"Trumpster\",\n",
    "    \"POTUS\",\n",
    "    \"@POTUS\",\n",
    "    \"Republican\",\n",
    "    \"Republicans\",\n",
    "    \"GOP\",\n",
    "    \"MAGA\",\n",
    "    \"Right Wing\",\n",
    "    \"the Right\",\n",
    "\n",
    "]\n",
    "frequent_names_biden = [\n",
    "    \"Biden\",\n",
    "    \"Joe Biden\",\n",
    "    \"@JoeBiden\",\n",
    "    \"The Biden\",\n",
    "    \"46\",\n",
    "    \"Joseph R. Biden\",\n",
    "    \"JRB\",\n",
    "    \"The Biden Administration\",\n",
    "    \"Bidenster\",\n",
    "    \"Joe\",\n",
    "    \"Joseph\",\n",
    "    \"Joseph Biden\",\n",
    "    \"Sleepy Joe\",\n",
    "    \"Uncle Joe\",\n",
    "    \"Dems\",\n",
    "    \"Democrat\",\n",
    "    \"Democrats\",\n",
    "    \"Left Wing\",\n",
    "    \"The Left\",\n",
    "]\n",
    "\n",
    "##Lower case all names\n",
    "frequent_names_trump = [name.lower() for name in frequent_names_trump]\n",
    "frequent_names_biden = [name.lower() for name in frequent_names_biden]\n",
    "\n",
    "# Create regex patterns from the lists of names\n",
    "pattern_trump = \"|\".join(frequent_names_trump)\n",
    "pattern_biden = \"|\".join(frequent_names_biden)\n",
    "\n",
    "# Create boolean masks where tweets contain any of the frequent names\n",
    "mask_trump = df[\"tweet\"].str.contains(pattern_trump, case=False, na=False)\n",
    "mask_biden = df[\"tweet\"].str.contains(pattern_biden, case=False, na=False)\n",
    "\n",
    "# Combine the masks to filter for tweets containing Trump names but not Biden names or vice versa\n",
    "filtered_tweets = df[(mask_trump & ~mask_biden) | (mask_biden & ~mask_trump)]\n",
    "\n",
    "# Count the number of filtered tweets\n",
    "count_filtered = filtered_tweets.shape[0]\n",
    "\n",
    "# Total number of tweets for percentage calculation\n",
    "total_tweets = len(df[\"tweet\"])\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    f\"Number of tweets containing Trump names but not Biden names, or vice versa: {count_filtered}\"\n",
    ")\n",
    "print(f\"Percentage of filtered tweets: {count_filtered / total_tweets * 100:.2f}%\")\n",
    "\n",
    "\n",
    "filtered_tweets_trump = df[mask_trump & ~mask_biden]\n",
    "filtered_tweets_biden = df[mask_biden & ~mask_trump]\n",
    "count_filtered_trump = filtered_tweets_trump.shape[0]\n",
    "count_filtered_biden = filtered_tweets_biden.shape[0]\n",
    "print(\n",
    "    f\"\\nNumber of tweets containing Trump names but not Biden names: {count_filtered_trump}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage of filtered tweets Trump: {count_filtered_trump / total_tweets * 100:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"\\nNumber of tweets containing Biden names but not Trump names: {count_filtered_biden}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage of filtered tweets Biden: {count_filtered_biden / total_tweets * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##show random 100 tweets in a new file  \n",
    "import random\n",
    "random.seed(42)\n",
    "random_trump_index = random.sample(range(0, count_filtered_trump), 100)\n",
    "random_biden_index = random.sample(range(0, count_filtered_biden), 100)\n",
    "with open(\"filtered_tweets.txt\" ,\"w\",encoding=\"UTF-8\") as file:\n",
    "    file.write(\"Trump Tweets\\n\")\n",
    "    for i in random_trump_index:\n",
    "        file.write(filtered_tweets_trump.iloc[i][\"tweet\"] + \"\\n\")\n",
    "    file.write(\"\\nBiden Tweets\\n\")\n",
    "    for i in random_biden_index:\n",
    "        file.write(filtered_tweets_biden.iloc[i][\"tweet\"] + \"\\n\")\n",
    "## Looking at the tweets there are some problems\n",
    "## 1. Some tweets are not in English\n",
    "## 2. Some tweets are empty ## never mind, I checked and there are no empty tweets\n",
    "## 3. Some hashtags are multiple words and are not separated by spaces\n",
    "## 4. Some tweets does not mention either Trump or Biden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State stats:\n",
      "state\n",
      "California                  33737\n",
      "New York                    25571\n",
      "Florida                     18228\n",
      "Texas                       18187\n",
      "District of Columbia         9755\n",
      "Illinois                     7652\n",
      "Pennsylvania                 7379\n",
      "New Jersey                   5441\n",
      "Massachusetts                5032\n",
      "Ohio                         4639\n",
      "Colorado                     4164\n",
      "North Carolina               4021\n",
      "Arizona                      3711\n",
      "Michigan                     3673\n",
      "Georgia                      3497\n",
      "Oregon                       3314\n",
      "Washington                   3089\n",
      "Virginia                     2924\n",
      "Tennessee                    2730\n",
      "Maryland                     2724\n",
      "Nevada                       2675\n",
      "Missouri                     2472\n",
      "Minnesota                    2159\n",
      "Wisconsin                    1918\n",
      "Indiana                      1682\n",
      "Kentucky                     1615\n",
      "South Carolina               1318\n",
      "Louisiana                    1291\n",
      "Connecticut                  1228\n",
      "Kansas                       1109\n",
      "Alabama                      1039\n",
      "Utah                          939\n",
      "Iowa                          937\n",
      "Vermont                       881\n",
      "Oklahoma                      870\n",
      "Hawaii                        824\n",
      "Puerto Rico                   659\n",
      "Arkansas                      654\n",
      "Idaho                         642\n",
      "New Mexico                    550\n",
      "North Dakota                  524\n",
      "Alaska                        496\n",
      "Nebraska                      482\n",
      "Maine                         447\n",
      "New Hampshire                 427\n",
      "West Virginia                 384\n",
      "Delaware                      350\n",
      "Rhode Island                  320\n",
      "Montana                       299\n",
      "Wyoming                       292\n",
      "Mississippi                   276\n",
      "South Dakota                  107\n",
      "Guam                            6\n",
      "Northern Mariana Islands        1\n",
      "dtype: int64\n",
      "\n",
      "Average tweets per state: 3691.50\n",
      "Standard deviation: 6387.43\n",
      "Median tweets per state: 1304.5\n",
      "\n",
      "Country stats:\n",
      "country\n",
      "United States of America    199341\n",
      "dtype: int64\n",
      "\n",
      "Number of empty tweets:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#combine the two dataframes\n",
    "df = pd.concat([filtered_tweets_trump, filtered_tweets_biden], ignore_index=True)\n",
    "# show stats for each state\n",
    "state_stats = df.groupby(\"state\").size().sort_values(ascending=False)\n",
    "print(\"\\nState stats:\")\n",
    "print(state_stats)\n",
    "# average, standard deviation, and median of tweets per state\n",
    "state_avg = df.groupby(\"state\").size().mean()\n",
    "state_std = df.groupby(\"state\").size().std()\n",
    "state_median = df.groupby(\"state\").size().median()\n",
    "print(f\"\\nAverage tweets per state: {state_avg:.2f}\")\n",
    "print(f\"Standard deviation: {state_std:.2f}\")\n",
    "print(f\"Median tweets per state: {state_median}\")\n",
    "# show counrty stats\n",
    "country_stats = df.groupby(\"country\").size().sort_values(ascending=False)\n",
    "print(\"\\nCountry stats:\")\n",
    "print(country_stats)\n",
    "##print number of empty tweets\n",
    "number_empty_tweets = df[\"tweet\"].str.len() == 0\n",
    "print(\"\\nNumber of empty tweets:\")\n",
    "print(number_empty_tweets.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mads is a loser : {'neg': 0.63, 'neu': 0.37, 'pos': 0.0, 'compound': -0.5267}\n",
      "madsisaloser : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "mads is a winner : {'neg': 0.0, 'neu': 0.345, 'pos': 0.655, 'compound': 0.5859}\n",
      "mads is a winner! : {'neg': 0.0, 'neu': 0.328, 'pos': 0.672, 'compound': 0.6239}\n",
      "the fbi named white supremacist groups as the biggest threat to homeland security. why does trump keep protecting them? : {'neg': 0.146, 'neu': 0.687, 'pos': 0.167, 'compound': -0.128}\n",
      "#LOSER : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "#DonaldTrump Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø¹Ù‡Ø¯Ø© ÙˆØ§Ø­Ø¯Ø© Ø®Ù„Ø§Ù„ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠÙ† Ø³Ù†Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© ØŒ Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ®Ø³Ø± Ø§Ù„Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ù…Ø±ØªÙŠÙ†. : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Contra todo pronÃ³stico, #DonaldTrump saliÃ³ de hospital dÃ­as despuÃ©s de confirmar su contagio de #coronavirus ğŸ¤” ğŸ¦ ğŸ¥ El doctor Juan Rivera revela detalles sobre su tratamiento milagroso ğŸ¥ https://t.co/E1Atjl4O7T : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Against all odds, #DonaldTrump left the hospital days after confirming his infection with the #coronavirus : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "trump es puta mierda : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "trump is a cunt : {'neg': 0.615, 'neu': 0.385, 'pos': 0.0, 'compound': -0.4939}\n",
      "This is the best day ever : {'neg': 0.0, 'neu': 0.543, 'pos': 0.457, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "\n",
    "test=[\"mads is a loser\",\"madsisaloser\",\"mads is a winner\",\"mads is a winner!\",\n",
    "      \"the fbi named white supremacist groups as the biggest threat to homeland security. why does trump keep protecting them?\",\"#LOSER\",\n",
    "      \"#DonaldTrump Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø¹Ù‡Ø¯Ø© ÙˆØ§Ø­Ø¯Ø© Ø®Ù„Ø§Ù„ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠÙ† Ø³Ù†Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© ØŒ Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ®Ø³Ø± Ø§Ù„Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ù…Ø±ØªÙŠÙ†.\",\n",
    "      \"Contra todo pronÃ³stico, #DonaldTrump saliÃ³ de hospital dÃ­as despuÃ©s de confirmar su contagio de #coronavirus ğŸ¤” ğŸ¦ ğŸ¥ El doctor Juan Rivera revela detalles sobre su tratamiento milagroso ğŸ¥ https://t.co/E1Atjl4O7T\",\n",
    "      \"Against all odds, #DonaldTrump left the hospital days after confirming his infection with the #coronavirus\",\n",
    "      \"trump es puta mierda\",\n",
    "      \"trump is a cunt\",\n",
    "      \"This is the best day ever\"]\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for i in test:\n",
    "    print(f\"{i} : {sid.polarity_scores(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA']\n",
      "['US']\n",
      "['America']\n",
      "['United', 'States']\n",
      "The US is the Best Country in the world! USA US America!!Â United States!\n",
      "['USA']\n",
      "['US']\n",
      "['America']\n",
      "['United', 'States']\n",
      "The US is the Best Country in the world! USA US America!!Â United States!\n",
      "The US is the Best Country in the world!   !!Â !\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import wordninja\n",
    "text = \"The US is the Best Country in the world! #USA #US #America!!Â #UnitedStates!\"\n",
    "\n",
    "def p(match):\n",
    "    a =wordninja.split(match.group())\n",
    "    print(a)\n",
    "    return \" \".join(a)\n",
    "\n",
    "# Replace all hashtags with \"REMOVED\"\n",
    "new_text = re.sub(r'#\\w+\\b', p, text)\n",
    "print(new_text)  # Welcome to REMOVED! REMOVED is REMOVED!\n",
    "\n",
    "# Or if you want to keep the # symbol:\n",
    "new_text = re.sub(r'#\\w+\\b', p, text)\n",
    "print(new_text)  # Welcome to #REMOVED! #REMOVED is #REMOVED!\n",
    "\n",
    "# Or replace with empty string to remove completely:\n",
    "new_text = re.sub(r'#\\w+\\b', '', text)\n",
    "print(new_text)  # Welcome to ! is !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
